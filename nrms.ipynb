{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NRMS: Neural News Recommendation with Multi-Head Self-Attention\n",
    "NRMS [1] is a neural news recommendation approach with multi-head selfattention. The core of NRMS is a news encoder and a user encoder. In the newsencoder, a multi-head self-attentions is used to learn news representations from news titles by modeling the interactions between words. In the user encoder, we learn representations of users from their browsed news and use multihead self-attention to capture the relatedness between the news. Besides, we apply additive attention to learn more informative news and user representations by selecting important words and news."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of NRMS:\n",
    "NRMS is a content-based neural news recommendation approach.\n",
    "It uses multi-self attention to learn news representations by modeling the iteractions between words and learn user representations by capturing the relationship between user browsed news.\n",
    "NRMS uses additive attentions to learn informative news and user representations by selecting important words and news."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set data\n",
    "\n",
    "Make sure you are under `LightRec/`. Run `mkdir data`.\n",
    "TODO...After you download data and unzip data...\n",
    "The data folder should look like\n",
    "```\n",
    "data/\n",
    "    train\n",
    "    valid\n",
    "    utils\n",
    "```\n",
    "Note that we are using the `small` version of the [MIND](https://msnews.github.io/) dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import lightrec\n",
    "`lightrec.model`\n",
    "* `lightrec.model.zoo`, store the recommender models here\n",
    "* `lightrec.model.zoo`, helper functions from model training\n",
    "`lightrec.data`\n",
    "* `lightrec.data`, access to specific dataset and its iterator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightrec.model import NRMS\n",
    "from lightrec.model.training import timer, params, cal_metric\n",
    "from lightrec.data import MindIterator\n",
    "from lightrec.data.tools import set_seed\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "set_seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------  --------------------------------------\n",
      "attention_hidden_dim   200\n",
      "batch_size             32\n",
      "data_format            news\n",
      "dropout                0.2\n",
      "epochs                 10\n",
      "head_dim               20\n",
      "head_num               20\n",
      "his_size               50\n",
      "learning_rate          0.0001\n",
      "loss                   cross_entropy_loss\n",
      "metrics                ['group_auc', 'mean_mrr', 'ndcg@5;10']\n",
      "model_type             nrms\n",
      "npratio                4\n",
      "optimizer              adam\n",
      "show_step              100000\n",
      "subvertDict_file       ./data/utils/subvert_dict.pkl\n",
      "support_quick_scoring  True\n",
      "title_size             30\n",
      "userDict_file          ./data/utils/uid2index.pkl\n",
      "vertDict_file          ./data/utils/vert_dict.pkl\n",
      "wordDict_file          ./data/utils/word_dict_all.pkl\n",
      "wordEmb_file           ./data/utils/embedding_all.npy\n",
      "word_emb_dim           300\n",
      "---------------------  --------------------------------------\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "param = params(for_model=\"nrms\",\n",
    "                   file=\"./data/utils/nrms.yaml\",\n",
    "                   wordDict_file=\"./data/utils/word_dict_all.pkl\",\n",
    "                   vertDict_file=\"./data/utils/vert_dict.pkl\",\n",
    "                   subvertDict_file=\"./data/utils/subvert_dict.pkl\",\n",
    "                   userDict_file=\"./data/utils/uid2index.pkl\",\n",
    "                   wordEmb_file=\"./data/utils/embedding_all.npy\")\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "print(param)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NRMS(param).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = \"./data/train/news.tsv\"\n",
    "user = \"./data/train/behaviors.tsv\"\n",
    "iterator = MindIterator(param)\n",
    "iterator.open(news, user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = \"./data/valid/news.tsv\"\n",
    "user = \"./data/valid/behaviors.tsv\"\n",
    "test_iterator = MindIterator(param)\n",
    "test_iterator.open(news, user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_iterator):\n",
    "    model.eval()\n",
    "    critical_size = 150\n",
    "    label_bag = model.offer_label_bag()\n",
    "    nrms_bag = model.offer_data_bag()\n",
    "    nrms_bag.append('user index')\n",
    "    group = {}\n",
    "    with torch.no_grad():\n",
    "        preds = {}\n",
    "        labels = {}\n",
    "        for bag in tqdm(\n",
    "                test_iterator.batch(data_bag=nrms_bag, test=True,\n",
    "                                    size=250)):\n",
    "            truth = bag[label_bag].squeeze()\n",
    "            pred = model(bag, scale=True,\n",
    "                            by_user=True).cpu().numpy().squeeze()\n",
    "            for i, tag in enumerate(bag['user index']):\n",
    "                if preds.get(tag, None):\n",
    "                    preds[tag].append(pred[i])\n",
    "                else:\n",
    "                    preds[tag] = [pred[i]]\n",
    "\n",
    "                if labels.get(tag, None):\n",
    "                    labels[tag].append(truth[i])\n",
    "                else:\n",
    "                    labels[tag] = [truth[i]]\n",
    "                    assert truth[i] == 1\n",
    "            del bag\n",
    "            # print(labels)\n",
    "        group_pred = []\n",
    "        group_label = []\n",
    "        names = list(preds)\n",
    "        for name in names:\n",
    "            group_pred.append(np.asarray(preds[name]))\n",
    "            group_label.append(np.asarray(labels[name]))\n",
    "    return cal_metric(group_label, group_pred, metrics=param.metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data bag\n",
    "To tell which parts of data are needed by NRMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_bag = model.offer_label_bag()\n",
    "nrms_bag = model.offer_data_bag()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One last step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), lr=param.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(param.epochs):\n",
    "    model = model.train()\n",
    "    with timer(name=\"epoch\"):\n",
    "        count, loss_epoch = 1, 0.\n",
    "        bar = tqdm(iterator.batch(data_bag=nrms_bag))\n",
    "        start_loss = None\n",
    "        for bag in bar:\n",
    "            pred = model(bag, by_user=True)\n",
    "            truth = bag[label_bag]\n",
    "            # print(pred.shape)\n",
    "            # print(truth.shape, pred.shape)\n",
    "            loss = model.loss(pred, truth)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            if start_loss is None:\n",
    "                start_loss = loss.item()\n",
    "            loss_epoch += loss.item()\n",
    "            bar.set_description(\n",
    "                f\"loss: {loss_epoch/count:.3f}/{start_loss:.3f}\")\n",
    "            count += 1\n",
    "            del bag\n",
    "            # print(f\"    {loss_epoch/count}\")\n",
    "    print()\n",
    "    loss_epoch /= count\n",
    "    report = evaluate(model, test_iterator)\n",
    "    print(f\"[{epoch+1}/{param.epochs}]: {loss_epoch:.3f} - {report}\")\n",
    "\n",
    "#     It gonna take a long time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another way\n",
    "Run `python -m lightrec.model._test`, you will step into the same training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "1. `download` function\n",
    "2. `annotation`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.3 64-bit ('torch': conda)",
   "language": "python",
   "name": "python36364bittorchcondab57438b0ebc343288464c1200ee6a711"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}